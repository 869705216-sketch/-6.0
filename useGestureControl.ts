// src/hooks/useGestureControl.ts
import { useCallback, useEffect, useRef, useState } from 'react';
import { TreeMode } from '../components/TreeScene';

export interface GestureState {
  mode: TreeMode;
  cameraActive: boolean;
}

export const useGestureControl = () => {
  const [gestureState, setGestureState] = useState<GestureState>({
    mode: 'FORMED',
    cameraActive: false,
  });

  const [cameraOffset, setCameraOffset] = useState({ x: 0, y: 0 });

  const videoRef = useRef<HTMLVideoElement | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const rafRef = useRef<number | null>(null);

  const initCameraStream = useCallback(async () => {
    try {
      if (streamRef.current) return;

      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'user', width: 640, height: 480 },
        audio: false,
      });

      const video = document.createElement('video');
      video.autoplay = true;
      video.playsInline = true;
      video.srcObject = stream;
      streamRef.current = stream;
      videoRef.current = video;

      video.onloadedmetadata = () => {
        video.play();
        setGestureState((s) => ({ ...s, cameraActive: true }));
        startGestureLoop();
      };
    } catch (err) {
      console.error('Camera init error', err);
    }
  }, []);

  const startGestureLoop = useCallback(() => {
    const loop = () => {
      const video = videoRef.current;
      if (!video || video.readyState < 2) {
        rafRef.current = requestAnimationFrame(loop);
        return;
      }

      // ==== è¿™é‡ŒæŽ¥å…¥æ‰‹åŠ¿æ£€æµ‹æ¨¡åž‹ ====
      // ä¼ªé€»è¾‘ï¼š
      //   1. ä»Ž video å½“å‰å¸§å–å›¾åƒ
      //   2. é€å…¥æ‰‹éƒ¨æ£€æµ‹æ¨¡åž‹ï¼Œå¾—åˆ°å…³é”®ç‚¹
      //   3. åˆ¤æ–­æ‰‹å¼ å¼€ / åˆæ‹¢ï¼ˆä¾‹å¦‚ï¼šäº”æŒ‡å¹³å‡é—´è·ï¼‰
      //   4. ä½¿ç”¨æ‰‹æŽŒä¸­å¿ƒ X / Y åç§»æ¥å½±å“ cameraOffset

      // ðŸ”¸ç¤ºä¾‹ï¼šå‡è®¾æˆ‘ä»¬æ‹¿åˆ°äº†ä»¥ä¸‹ç»“æžœï¼š
      // const isHandOpen = ...boolean
      // const normX = ... [-1, 1]
      // const normY = ... [-1, 1]

      // è¿™é‡Œå…ˆç”¨ç®€å•çš„â€œä¼ªéšæœºæ‘†åŠ¨â€åšå ä½ï¼Œæ–¹ä¾¿ä½ çœ‹æ•ˆæžœï¼š
      const t = performance.now() * 0.001;
      const fakeOpen = Math.sin(t * 0.7) > 0.2; // æ‰‹åŠ¿å¼€å…³å ä½
      const normX = Math.sin(t * 0.4) * 0.4;
      const normY = Math.cos(t * 0.6) * 0.3;

      setGestureState((s) => ({
        ...s,
        mode: fakeOpen ? 'CHAOS' : 'FORMED',
      }));

      setCameraOffset({
        x: normX * 4, // æŽ§åˆ¶æ°´å¹³ç»•è¡Œ
        y: normY * 2, // æŽ§åˆ¶ä»°ä¿¯
      });

      rafRef.current = requestAnimationFrame(loop);
    };

    rafRef.current = requestAnimationFrame(loop);
  }, []);

  useEffect(() => {
    return () => {
      if (rafRef.current) cancelAnimationFrame(rafRef.current);
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((t) => t.stop());
      }
    };
  }, []);

  return {
    gestureState,
    cameraOffset,
    initCameraStream,
  };
};
